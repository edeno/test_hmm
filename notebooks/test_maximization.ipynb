{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jax import lax\n",
    "from jax import vmap\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "\n",
    "def _normalize(u, axis=0, eps=1e-15):\n",
    "    \"\"\"Normalizes the values within the axis in a way that they sum up to 1.\n",
    "    Args:\n",
    "        u: Input array to normalize.\n",
    "        axis: Axis over which to normalize.\n",
    "        eps: Minimum value threshold for numerical stability.\n",
    "    Returns:\n",
    "        Tuple of the normalized values, and the normalizing denominator.\n",
    "    \"\"\"\n",
    "    u = jnp.where(u == 0, 0, jnp.where(u < eps, eps, u))\n",
    "    c = u.sum(axis=axis)\n",
    "    c = jnp.where(c == 0, 1, c)\n",
    "    return u / c, c\n",
    "\n",
    "\n",
    "# Helper functions for the two key filtering steps\n",
    "def _condition_on(probs, ll):\n",
    "    \"\"\"Condition on new emissions, given in the form of log likelihoods\n",
    "    for each discrete state, while avoiding numerical underflow.\n",
    "    Args:\n",
    "        probs(k): prior for state k\n",
    "        ll(k): log likelihood for state k\n",
    "    Returns:\n",
    "        probs(k): posterior for state k\n",
    "    \"\"\"\n",
    "    ll_max = ll.max()\n",
    "    new_probs = probs * jnp.exp(ll - ll_max)\n",
    "    new_probs, norm = _normalize(new_probs)\n",
    "    log_norm = jnp.log(norm) + ll_max\n",
    "    return new_probs, log_norm\n",
    "\n",
    "\n",
    "def _predict(probs, A):\n",
    "    return A.T @ probs\n",
    "\n",
    "\n",
    "@partial(jit)\n",
    "def hmm_filter(\n",
    "    initial_distribution,\n",
    "    transition_matrix,\n",
    "    log_likelihoods,\n",
    "):\n",
    "    r\"\"\"Forwards filtering\n",
    "    Transition matrix may be either 2D (if transition probabilities are fixed) or 3D\n",
    "    if the transition probabilities vary over time. Alternatively, the transition\n",
    "    matrix may be specified via `transition_fn`, which takes in a time index $t$ and\n",
    "    returns a transition matrix.\n",
    "    Args:\n",
    "        initial_distribution: $p(z_1 \\mid u_1, \\theta)$\n",
    "        transition_matrix: $p(z_{t+1} \\mid z_t, u_t, \\theta)$\n",
    "        log_likelihoods: $p(y_t \\mid z_t, u_t, \\theta)$ for $t=1,\\ldots, T$.\n",
    "    Returns:\n",
    "        filtered posterior distribution\n",
    "    \"\"\"\n",
    "    num_timesteps, num_states = log_likelihoods.shape\n",
    "\n",
    "    def _step(carry, t):\n",
    "        log_normalizer, predicted_probs = carry\n",
    "\n",
    "        ll = log_likelihoods[t]\n",
    "\n",
    "        filtered_probs, log_norm = _condition_on(predicted_probs, ll)\n",
    "        log_normalizer += log_norm\n",
    "        predicted_probs_next = _predict(filtered_probs, transition_matrix)\n",
    "\n",
    "        return (log_normalizer, predicted_probs_next), (filtered_probs, predicted_probs)\n",
    "\n",
    "    carry = (0.0, initial_distribution)\n",
    "    (log_normalizer, _), (filtered_probs, predicted_probs) = lax.scan(_step, carry, jnp.arange(num_timesteps))\n",
    "\n",
    "    return log_normalizer, filtered_probs, predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-1.1920929e-07, dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.hmm3 import forward\n",
    "\n",
    "initial_distribution = np.asarray([0.9, 0.1])\n",
    "transition_matrix = np.asarray([[0.9, 0.1],\n",
    "                                 [0.1, 0.9]])\n",
    "log_likelihoods = np.zeros((9, 2))\n",
    "\n",
    "marginal_likelihood, _, _ = hmm_filter(\n",
    "    initial_distribution,\n",
    "    transition_matrix,\n",
    "    log_likelihoods,\n",
    ")\n",
    "marginal_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.nn import softmax\n",
    "\n",
    "\n",
    "def centered_softmax_forward(y):\n",
    "    \"\"\"`softmax(x) = exp(x-c) / sum(exp(x-c))` where c is the last coordinate\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    > y = np.log([2, 3, 4])\n",
    "    > np.allclose(centered_softmax_forward(y), [0.2, 0.3, 0.4, 0.1])\n",
    "    \"\"\"\n",
    "    if y.ndim == 1:\n",
    "        y = jnp.append(y, 0)\n",
    "    else:\n",
    "        y = jnp.column_stack((y,  jnp.zeros((y.shape[0],))))\n",
    "\n",
    "    return softmax(y, axis=-1)\n",
    "\n",
    "\n",
    "def centered_softmax_inverse(y):\n",
    "    \"\"\"`softmax(x) = exp(x-c) / sum(exp(x-c))` where c is the last coordinate\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    > y = np.asarray([0.2, 0.3, 0.4, 0.1])\n",
    "    > np.allclose(np.exp(centered_softmax_inverse(y)), np.asarray([2,3,4]))\n",
    "    \"\"\"\n",
    "    return jnp.log(y[..., :-1]) - jnp.log(y[..., -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import jax\n",
    "from src.simulate import simulate_two_state_poisson\n",
    "\n",
    "\n",
    "sampling_frequency = 500\n",
    "time, true_rate, spikes = simulate_two_state_poisson(\n",
    "    sampling_frequency=sampling_frequency\n",
    ")\n",
    "\n",
    "n_states = 2\n",
    "n_time = spikes.shape[0]\n",
    "initial_distribution = np.ones((n_states,)) / n_states\n",
    "transition_matrix = np.asarray([[0.98, 0.02], [0.02, 0.98]])\n",
    "is_training = np.ones((n_time,), dtype=bool)\n",
    "is_training[: n_time // 2] = False\n",
    "\n",
    "n_rate_parameters = 1\n",
    "n_rates = n_states * n_rate_parameters\n",
    "\n",
    "@jax.jit\n",
    "def neglogp(log_parameters):\n",
    "    unconstrained_rates = log_parameters[:n_rates]\n",
    "    unconstrained_initial_distribution = log_parameters[n_rates:n_rates+n_states + 1]\n",
    "    unconstrained_transition_matrix = log_parameters[n_rates+n_states + 1:]\n",
    "    \n",
    "    rates = jnp.exp(unconstrained_rates)\n",
    "    initial_distribution = centered_softmax_inverse(unconstrained_initial_distribution)\n",
    "    transition_matrix = centered_softmax_inverse(unconstrained_transition_matrix.reshape((n_states, n_states + 1), order=\"F\"))\n",
    "    \n",
    "    likelihood = jax.scipy.stats.poisson.logpmf(spikes[:, jnp.newaxis], rates)\n",
    "\n",
    "    marginal_likelihood, _, _ = hmm_filter(\n",
    "        initial_distribution, transition_matrix, log_likelihoods\n",
    "    )\n",
    "    \n",
    "    return -marginal_likelihood\n",
    "\n",
    "dlike = jax.grad(neglogp)\n",
    "\n",
    "x0 = np.concatenate((np.log([spikes[is_training].mean(), spikes[~is_training].mean()]), centered_softmax_forward(initial_distribution), centered_softmax_forward(transition_matrix).ravel()))\n",
    "\n",
    "res = minimize(\n",
    "    neglogp, x0=x0, method=\"BFGS\", jac=dlike,\n",
    ")\n",
    "\n",
    "log_parameters = res.x\n",
    "unconstrained_rates = log_parameters[:n_rates]\n",
    "unconstrained_initial_distribution = log_parameters[n_rates:n_rates+n_states + 1]\n",
    "unconstrained_transition_matrix = log_parameters[n_rates+n_states + 1:]\n",
    "estimated_rates = jnp.exp(unconstrained_rates)\n",
    "estimated_initial_distribution = centered_softmax_inverse(unconstrained_initial_distribution)\n",
    "estimated_transition_matrix = centered_softmax_inverse(unconstrained_transition_matrix.reshape((n_states, n_states + 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_initial_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([14.150001, 10.500001], dtype=float32), array([ 5., 20.]))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_rates * sampling_frequency, np.unique(true_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.3310811 , 0.3310811 ],\n",
       "       [0.00675676, 0.3310811 ]], dtype=float32)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unconstrained_rates = log_parameters[:n_rates]\n",
    "unconstrained_initial_distribution = log_parameters[n_rates:n_rates+n_states]\n",
    "unconstrained_transition_matrix = log_parameters[n_rates+n_states:]\n",
    "\n",
    "jnp.exp(unconstrained_rates)\n",
    "centered_softmax_forward(unconstrained_initial_distribution)\n",
    "centered_softmax_forward(unconstrained_transition_matrix).reshape((n_states, n_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.3639016 , -3.92713664])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unconstrained_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.exp(x0[:2]), jnp.exp(log_parameters[:n_rates]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.01960784, 0.9607844 , 0.01960784], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " centered_softmax_forward(unconstrained_initial_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.7,  9.5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(x0) * sampling_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(centered_softmax_inverse(centered_softmax_forward(transition_matrix)), transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def centered_softmax_inverse(y):\n",
    "    \"\"\"`softmax(x) = exp(x-c) / sum(exp(x-c))` where c is the last coordinate\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    > y = np.asarray([0.2, 0.3, 0.4, 0.1])\n",
    "    > np.allclose(np.exp(centered_softmax_inverse(y)), np.asarray([2,3,4]))\n",
    "    \"\"\"\n",
    "    return jnp.log(y[..., :-1]) - jnp.log(y[..., -1])\n",
    "\n",
    "y = np.asarray([0.2, 0.3, 0.4, 0.1])\n",
    "np.allclose(np.exp(centered_softmax_inverse(y)), np.asarray([2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax.nn import softmax\n",
    "\n",
    "\n",
    "def centered_softmax_forward(y):\n",
    "    \"\"\"`softmax(x) = exp(x-c) / sum(exp(x-c))` where c is the last coordinate\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    > y = np.log([2, 3, 4])\n",
    "    > np.allclose(centered_softmax_forward(y), [0.2, 0.3, 0.4, 0.1])\n",
    "    \"\"\"\n",
    "    if y.ndim == 1:\n",
    "        y = jnp.append(y, 0)\n",
    "    else:\n",
    "        y = jnp.column_stack((y,  jnp.zeros((y.shape[0],))))\n",
    "\n",
    "    return softmax(y, axis=-1)\n",
    "\n",
    "y = np.log([2, 3, 4])\n",
    "np.allclose(centered_softmax_forward(y), [0.2, 0.3, 0.4, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.2, 0.3, 0.4, 0.1]], dtype=float32)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.log([[2, 3, 4]])\n",
    "centered_softmax_forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.3, 0.4, 0.1],\n",
       "       [0.2, 0.3, 0.4, 0.1],\n",
       "       [0.2, 0.3, 0.4, 0.1]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.log([[2, 3, 4],\n",
    "            [2, 3, 4],\n",
    "            [2, 3, 4]])\n",
    "\n",
    "centered_softmax_forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6c357aac43d0ff46917fb823d0877c209998debada17a7fc46c62b2ec31f1f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
