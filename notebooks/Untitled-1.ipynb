{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(initial_conditions, likelihood, transition_matrix):\n",
    "\n",
    "    LOG_EPS = 1e-16\n",
    "    n_time, n_states = likelihood.shape\n",
    "\n",
    "    log_likelihood = np.log(likelihood + LOG_EPS)\n",
    "    log_state_transition = np.log(transition_matrix + LOG_EPS)\n",
    "    log_initial_conditions = np.log(initial_conditions + LOG_EPS)\n",
    "\n",
    "    path_log_prob = np.ones_like(likelihood)\n",
    "    back_pointer = np.zeros_like(likelihood, dtype=int)\n",
    "\n",
    "    path_log_prob[0] = log_initial_conditions + log_likelihood[0]\n",
    "\n",
    "    for time_ind in range(1, n_time):\n",
    "        prior = path_log_prob[time_ind - 1] + log_state_transition\n",
    "        for state_ind in range(n_states):\n",
    "            back_pointer[time_ind, state_ind] = np.argmax(prior[state_ind])\n",
    "            path_log_prob[time_ind, state_ind] = (\n",
    "                prior[state_ind, back_pointer[time_ind, state_ind]]\n",
    "                + log_likelihood[time_ind, state_ind]\n",
    "            )\n",
    "\n",
    "    # Find the best accumulated path prob in the last time bin\n",
    "    # and then trace back the best path\n",
    "    best_path = np.zeros((n_time,), dtype=int)\n",
    "    best_path[-1] = np.argmax(path_log_prob[-1])\n",
    "    for time_ind in range(n_time - 2, -1, -1):\n",
    "        best_path[time_ind] = back_pointer[time_ind + 1, best_path[time_ind + 1]]\n",
    "\n",
    "    return best_path, np.exp(np.max(path_log_prob[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 2, 1, 1, 1, 1, 1, 0]), 4.3584805012498837e-20)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.test_hmm import generate_data, generate_data3\n",
    "\n",
    "(\n",
    "    initial_conditions,\n",
    "    transition_matrix,\n",
    "    emission_matrix,\n",
    "    _,\n",
    "    observations_ind,\n",
    ") = generate_data3()\n",
    "\n",
    "likelihood = get_likelihood(emission_matrix, observations_ind)\n",
    "\n",
    "best_path, path_prob = viterbi(initial_conditions, likelihood, transition_matrix)\n",
    "best_path, path_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 2, 2, 2, 1]), 0.00012541132800000045)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hmm import get_likelihood\n",
    "from src.test_hmm import generate_data, generate_data3\n",
    "\n",
    "# prob_pathefine model parameters\n",
    "transition_matrix = np.array([[0.8, 0.1, 0.1], \n",
    "              [0.2, 0.7, 0.1], \n",
    "              [0.1, 0.3, 0.6]])\n",
    "\n",
    "initial_conditions = np.array([0.6, 0.2, 0.2])\n",
    "\n",
    "emission_matrix = np.array([[0.7, 0.0, 0.3], \n",
    "                            [0.1, 0.9, 0.0], \n",
    "                            [0.0, 0.2, 0.8]])\n",
    "\n",
    "\n",
    "observations_ind = np.array([0, 2, 0, 2, 2, 1]).astype(np.int32)\n",
    "\n",
    "likelihood = get_likelihood(emission_matrix.T, observations_ind)\n",
    "\n",
    "best_path, path_prob = viterbi(initial_conditions, likelihood, transition_matrix)\n",
    "best_path, path_prob\n",
    "\n",
    "# [0.336 0.004 0.   ]\n",
    "# [0.042 0.014 0.   ]\n",
    "# [0.042 0.002 0.   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0]), 2.6011238399999947e-19)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hmm import viterbi\n",
    "import numpy as np\n",
    "from src.hmm import get_likelihood\n",
    "\n",
    "# Define model parameters\n",
    "transition_matrix = np.array([[0.8, 0.1, 0.1], \n",
    "              [0.2, 0.7, 0.1], \n",
    "              [0.1, 0.3, 0.6]])\n",
    "\n",
    "initial_conditions = np.array([0.6, 0.2, 0.2])\n",
    "\n",
    "emission_matrix = np.array([[0.7, 0.0, 0.3], \n",
    "              [0.1, 0.9, 0.0], \n",
    "              [0.0, 0.2, 0.8]])\n",
    "\n",
    "\n",
    "observations_ind = np.array([0, 2, 0, 2, 2, 1]).astype(np.int32)\n",
    "\n",
    "likelihood = get_likelihood(emission_matrix, observations_ind)\n",
    "\n",
    "viterbi(initial_conditions, likelihood, transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi2(initial_conditions, likelihood, transition_matrix):\n",
    "\n",
    "    LOG_EPS = 1e-16\n",
    "    n_time, n_states = likelihood.shape\n",
    "\n",
    "    log_likelihood = np.log(likelihood + LOG_EPS)\n",
    "    log_state_transition = np.log(transition_matrix + LOG_EPS)\n",
    "    log_initial_conditions = np.log(initial_conditions + LOG_EPS)\n",
    "\n",
    "    path_log_prob = np.ones_like(likelihood)\n",
    "    back_pointer = np.zeros_like(likelihood, dtype=int)\n",
    "\n",
    "    path_log_prob[0] = log_initial_conditions + log_likelihood[0]\n",
    "\n",
    "    for time_ind in range(1, n_time):\n",
    "        prior = path_log_prob[time_ind - 1] + log_state_transition\n",
    "        for state_ind in range(n_states):\n",
    "            back_pointer[time_ind, state_ind] = np.argmax(prior[state_ind])\n",
    "            path_log_prob[time_ind, state_ind] = (\n",
    "                prior[state_ind, back_pointer[time_ind, state_ind]]\n",
    "                + log_likelihood[time_ind, state_ind]\n",
    "            )\n",
    "\n",
    "    # Find the best accumulated path prob in the last time bin\n",
    "    # and then trace back the best path\n",
    "    best_path = np.empty((n_time,), dtype=int)\n",
    "    best_path[-1] = np.argmax(path_log_prob[-1])\n",
    "    for time_ind in range(n_time - 2, -1, -1):\n",
    "        best_path[time_ind] = back_pointer[time_ind + 1, best_path[time_ind + 1]]\n",
    "\n",
    "    return best_path, np.exp(np.max(path_log_prob[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 1]), 0.0005852528640000015)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi2(initial_conditions, likelihood, transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_information_criterion(log_likelihood, n_states, n_independent_parameters, n_time=1):\n",
    "    n_parameters = n_states**2 + n_independent_parameters * n_states - 1\n",
    "    aic = -2 * log_likelihood + 2 * n_parameters\n",
    "    bic = -2 * log_likelihood + n_parameters * np.log(n_time)\n",
    "    \n",
    "    return aic, bic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('test_hmm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7430815ce57fe787854a3531a1da753d6c88b1e899f537a047c4da845fb9b2e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
